{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "\n",
    "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
    "    # then we get the max (or min or avg)\n",
    "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "\n",
    "    # we remove the TripType now, and concat training and testing data\n",
    "    # the concat is done so that we have the same columns for both datasets\n",
    "    # after one-hot encoding\n",
    "    df_train = df_train.drop(\"TripType\", axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    # the next three operations are the ones we have just presented in the previous lines\n",
    "    \n",
    "    # drop the columns we won't use (it may be good to use them somehow)\n",
    "    df = df.drop([\"Upc\", \"FinelineNumber\"], axis=1)\n",
    "\n",
    "    # one-hot encoding for the DepartmentDescription\n",
    "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "\n",
    "    # now we add the groupby values\n",
    "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
    "    \n",
    "    # finally, we do one-hot encoding for the Weekday\n",
    "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
    "\n",
    "    # get train and test back\n",
    "    df_train = df[df.is_train_set != 0]\n",
    "    df_test = df[df.is_train_set == 0]\n",
    "    \n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results dataframe is used to store the computed results\n",
    "results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use a DesicionTree to classify and GridSearch to determine the parameters\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_param = {'criterion':('gini', 'entropy'), 'min_samples_leaf':(1, 2, 5),\n",
    "              'min_samples_split':(2, 3, 5, 10, 50, 100)}\n",
    "tree = DT(random_state=42)\n",
    "tree_clf = GridSearchCV(tree, tree_param, cv=3, scoring='accuracy') #scoring='balanced_accuracy')\n",
    "tree_clf.fit(X_train, y_train)\n",
    "best_tree_clf = tree_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.6304134697357204\n",
      "DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=100,\n",
      "                       random_state=42)\n",
      "The best classifier so far is: \n",
      "DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=100,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print('Best Decision Tree accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = best_tree_clf.predict(X_train)\n",
    "y_test_pred = best_tree_clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6757033248081842\n",
      "Test Accuracy:  0.6344422895221046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print('Train Accuracy: ', np.sum(y_train_pred == y_train)/len(y_train))\n",
    "print('Test Accuracy: ', np.sum(y_test_pred == y_valid)/len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error:2.09e+04\n",
      "Test error:2.27e+04\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n (evaluate):\n",
    "train_error_multiple = mean_squared_error(y_train, y_train_pred)\n",
    "test_error_multiple = mean_squared_error(y_valid, y_test_pred)\n",
    "print(f'Train error:{train_error_multiple:0.3}')\n",
    "print(f'Test error:{test_error_multiple:0.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 250, num = 4)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 3)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = GridSearchCV(model, random_grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lborgnino/miniconda3/envs/diplodatos-ayvd/lib/python3.6/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [10, 60, 110, None],\n",
       "                         'max_features': ['auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 116, 183, 250]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 183}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = best_random.predict(X_train)\n",
    "y_test_pred = best_random.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8599744245524297\n",
      "Test Accuracy:  0.671490377442936\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy: ', np.sum(y_train_pred == y_train)/len(y_train))\n",
    "print('Test Accuracy: ', np.sum(y_test_pred == y_valid)/len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error:1.96e+04\n",
      "Test error:2.22e+04\n"
     ]
    }
   ],
   "source": [
    "# Evaluaci√≥n (evaluate):\n",
    "train_error_multiple = mean_squared_error(y_train, y_train_pred)\n",
    "test_error_multiple = mean_squared_error(y_valid, y_test_pred)\n",
    "print(f'Train error:{train_error_multiple:0.3}')\n",
    "print(f'Test error:{test_error_multiple:0.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lborgnino/miniconda3/envs/diplodatos-ayvd/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/lborgnino/miniconda3/envs/diplodatos-ayvd/lib/python3.6/site-packages/pandas/core/generic.py:8765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "X_train.ScanCount[X_train.ScanCount < 0 ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.logspace(0, 4, num=4)\n",
    "penalty = ['l1', 'l2']\n",
    "solver = ['liblinear', 'saga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = dict(penalty=penalty, solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(model, hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Accuracy: ', np.sum(y_train_pred == y_train)/len(y_train))\n",
    "print('Test Accuracy: ', np.sum(y_test_pred == y_valid)/len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluaci√≥n (evaluate):\n",
    "train_error_multiple = mean_squared_error(y_train, y_train_pred)\n",
    "test_error_multiple = mean_squared_error(y_valid, y_test_pred)\n",
    "print(f'Train error:{train_error_multiple:0.3}')\n",
    "print(f'Test error:{test_error_multiple:0.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:diplodatos-ayvd] *",
   "language": "python",
   "name": "conda-env-diplodatos-ayvd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
